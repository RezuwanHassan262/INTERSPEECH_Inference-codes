{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37174,"databundleVersionId":3938797,"sourceType":"competition"},{"sourceId":3886074,"sourceType":"datasetVersion","datasetId":2308987},{"sourceId":3889637,"sourceType":"datasetVersion","datasetId":2311133},{"sourceId":4142276,"sourceType":"datasetVersion","datasetId":2446557},{"sourceId":4143520,"sourceType":"datasetVersion","datasetId":2447262},{"sourceId":7786721,"sourceType":"datasetVersion","datasetId":4557587}],"dockerImageVersionId":30204,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"wav input has been cast to required mp3 keys using the following code\n  \n    df.path = df.path.apply(lambda x: post_process_keys(x))","metadata":{}},{"cell_type":"code","source":"!cp -r ../input/python-packages2 ./","metadata":{"execution":{"iopub.status.busy":"2024-03-08T08:01:39.300530Z","iopub.execute_input":"2024-03-08T08:01:39.300875Z","iopub.status.idle":"2024-03-08T08:01:40.686698Z","shell.execute_reply.started":"2024-03-08T08:01:39.300792Z","shell.execute_reply":"2024-03-08T08:01:40.685497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar xvfz ./python-packages2/jiwer.tgz\n!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n!tar xvfz ./python-packages2/normalizer.tgz\n!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n!tar xvfz ./python-packages2/pyctcdecode.tgz\n!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n\n!tar xvfz ./python-packages2/pypikenlm.tgz\n!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T08:01:40.688969Z","iopub.execute_input":"2024-03-08T08:01:40.689339Z","iopub.status.idle":"2024-03-08T08:03:13.779213Z","shell.execute_reply.started":"2024-03-08T08:01:40.689305Z","shell.execute_reply":"2024-03-08T08:03:13.777862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom glob import glob\nfrom transformers import AutoFeatureExtractor, pipeline\nimport pandas as pd\nimport librosa\nimport IPython\nfrom datasets import load_metric\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport gc\nimport wave\nfrom scipy.io import wavfile\nimport scipy.signal as sps\nimport pyctcdecode\n\ntqdm.pandas()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T08:03:13.780924Z","iopub.execute_input":"2024-03-08T08:03:13.781275Z","iopub.status.idle":"2024-03-08T08:03:25.007372Z","shell.execute_reply.started":"2024-03-08T08:03:13.781239Z","shell.execute_reply":"2024-03-08T08:03:25.006406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHANGE ACCORDINGLY\nBATCH_SIZE = 16\nTEST_DIRECTORY = '/kaggle/input/local-stt-for-now/local_speech_for_now/tangail'\n\npath1 = glob(os.path.join(TEST_DIRECTORY,'*.wav'))\npaths = path1","metadata":{"execution":{"iopub.status.busy":"2024-03-08T09:24:15.125093Z","iopub.execute_input":"2024-03-08T09:24:15.125486Z","iopub.status.idle":"2024-03-08T09:24:15.137190Z","shell.execute_reply.started":"2024-03-08T09:24:15.125451Z","shell.execute_reply":"2024-03-08T09:24:15.136345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    my_model_name = '../input/yellowking-dlsprint-model/YellowKing_model'\n    processor_name = '../input/yellowking-dlsprint-model/YellowKing_processor'\n\n\nfrom transformers import Wav2Vec2ProcessorWithLM\n\nprocessor = Wav2Vec2ProcessorWithLM.from_pretrained(CFG.processor_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T09:24:20.793362Z","iopub.execute_input":"2024-03-08T09:24:20.794475Z","iopub.status.idle":"2024-03-08T09:25:31.396584Z","shell.execute_reply.started":"2024-03-08T09:24:20.794435Z","shell.execute_reply":"2024-03-08T09:25:31.395650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_asrLM = pipeline(\"automatic-speech-recognition\", model=CFG.my_model_name ,feature_extractor =processor.feature_extractor, tokenizer= processor.tokenizer,decoder=processor.decoder ,device=0)\n\n\n# speech, sr = librosa.load('/kaggle/input/bengaliai-speech/test_mp3s/0f3dac00655e.mp3', sr=processor.feature_extractor.sampling_rate)\n\n# my_asrLM([speech]*2, chunk_length_s=112, stride_length_s=None)\n\n# my_asrLM\n\n\n\nclass AudioDataset(Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self,idx):\n        speech, sr = librosa.load(self.paths[idx], sr=processor.feature_extractor.sampling_rate) \n#         print(speech.shape)\n        return speech\n\n\ndataset = AudioDataset(paths)\n#dataset[0]\ndevice = 'cuda:0'\n\ndef collate_fn_padd(batch):\n    '''\n    Padds batch of variable length\n\n    note: it converts things ToTensor manually here since the ToTensor transform\n    assume it takes in images rather than arbitrary tensors.\n    '''\n    ## get sequence lengths\n    lengths = torch.tensor([ t.shape[0] for t in batch ])\n    ## padd\n    batch = [ torch.Tensor(t) for t in batch ]\n    batch = torch.nn.utils.rnn.pad_sequence(batch)\n    ## compute mask\n    mask = (batch != 0)\n    return batch, lengths, mask\n\n\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=8, collate_fn=collate_fn_padd)\n\n\n\npreds_all = []\nfor batch, lengths, mask in dataloader:\n    preds = my_asrLM(list(batch.numpy().transpose()))\n    preds_all+=preds\n\n\n\nfrom bnunicodenormalizer import Normalizer \n\n\nbnorm = Normalizer()\ndef normalize(sen):\n    _words = [bnorm(word)['normalized']  for word in sen.split()]\n    return \" \".join([word for word in _words if word is not None])\n\ndef dari(sentence):\n    try:\n        if sentence[-1]!=\"ред\":\n            sentence+=\"ред\"\n    except:\n        print(sentence)\n    return sentence\n\n\ndf1= pd.DataFrame(\n    {\n        \"External_ID\":[p.split(os.sep)[-1].replace('.wav','') for p in paths],\n        \"content\":[p['text']for p in preds_all]\n    }\n)\ndf1.content= df1.content.apply(lambda x:normalize(x))\ndf1.content= df1.content.apply(lambda x:dari(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-08T09:25:31.398265Z","iopub.execute_input":"2024-03-08T09:25:31.398601Z","iopub.status.idle":"2024-03-08T10:27:35.082103Z","shell.execute_reply.started":"2024-03-08T09:25:31.398569Z","shell.execute_reply":"2024-03-08T10:27:35.080945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:37:00.409846Z","iopub.execute_input":"2024-03-08T10:37:00.410293Z","iopub.status.idle":"2024-03-08T10:37:00.423747Z","shell.execute_reply.started":"2024-03-08T10:37:00.410254Z","shell.execute_reply":"2024-03-08T10:37:00.422415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.to_csv(\"2.6 tangail-yellowking-inference.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:42:31.173792Z","iopub.execute_input":"2024-03-08T10:42:31.174276Z","iopub.status.idle":"2024-03-08T10:42:31.191505Z","shell.execute_reply.started":"2024-03-08T10:42:31.174224Z","shell.execute_reply":"2024-03-08T10:42:31.190391Z"},"trusted":true},"execution_count":null,"outputs":[]}]}